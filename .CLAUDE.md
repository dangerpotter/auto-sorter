# Praxis Auto Sorter

A local web application that automates the quarterly task of setting up Praxis bots (in-course AI assistants) for Capella University courses. It processes Canvas LMS reports and helps assign instructors to the appropriate Course Aide bots, generating JSON configuration files for Praxis LTI context.

## Tech Stack

- **Backend:** Node.js + Express.js (port 3000)
- **Frontend:** HTML5 SPA with TailwindCSS (via CDN)
- **Database:** SQLite (`praxis_database.db`)
- **CSV Parsing:** PapaParse (client-side, via CDN)
- **Utilities:** Python 3 + Tkinter (2 standalone GUI tools)

## Project Structure

```
praxis_auto_sorter/
├── Quick_sort_app.html    # Main SPA - ALL frontend UI and logic (~500 lines)
├── server.js              # Express server entry point, serves static files + API
├── database.js            # SQLite initialization and schema creation
├── package.json           # Node.js dependencies
├── praxis_database.db     # SQLite database (auto-created)
├── add_url_script.py      # Utility: Convert course IDs to URLs (Tkinter GUI)
├── json_course_comparison.py  # Utility: Compare/diff JSON course lists (Tkinter GUI)
├── memory-bank/           # Detailed technical documentation
│   ├── projectbrief.md    # Project goals and scope
│   ├── productContext.md  # User experience goals
│   ├── techContext.md     # Technology details
│   ├── systemPatterns.md  # Architecture patterns
│   ├── api_documentation.md  # API endpoint specs
│   └── databaseContext.md # Database schema details
└── [output folders]/      # Generated CSV/JSON files from runs (e.g., fall2025/)
```

## Key File Locations

| Task | File | Notes |
|------|------|-------|
| Frontend UI/logic | `Quick_sort_app.html` | Single file SPA, all 6 workflow steps |
| API endpoints | `server.js` | GET/POST `/api/runs` |
| Database schema | `database.js` | `provisioning_runs` table |
| Detailed docs | `memory-bank/` | Reference for deep dives |

## Application Workflow

The app guides users through a 6-step process:

1. **Step 0 - Run Configuration:** Name the provisioning run, view past runs
2. **Step 1 - File Upload:** Upload 4 CSVs (enrollments, courses, users, bots)
3. **Step 2 - Column Mapping:** Map CSV columns to required fields
4. **Step 3 - Role Selection:** Select which roles represent instructors
5. **Step 4 - Instructor Assignment:** Two-panel UI to assign instructors to bots
6. **Step 5 - Generate JSON:** Output bot-grouped JSON files with course URLs

## Data Flow

```
CSV Files → PapaParse (browser) → Column Mapping → Filter by Role
    → Join enrollments + courses + users → Instructor List
    → Manual Assignment to Bots → Generate JSON URLs
    → Save to SQLite via POST /api/runs
```

## Database Schema

Single table: `provisioning_runs`
- `id` INTEGER PRIMARY KEY AUTOINCREMENT
- `runName` TEXT NOT NULL UNIQUE (e.g., "Fall 2025")
- `createdAt` DATETIME DEFAULT CURRENT_TIMESTAMP
- `jsonData` TEXT (stringified JSON of all bot assignments)

## API Endpoints

| Method | Endpoint | Purpose |
|--------|----------|---------|
| GET | `/api/runs` | Fetch all past provisioning runs |
| POST | `/api/runs` | Save a new run (body: `{runName, jsonData}`) |

## Common Development Tasks

### Adding a new workflow step
- Edit `Quick_sort_app.html`
- Add new step div with `id="stepX"`
- Update `navigateToStep()` function
- Add step button handlers

### Modifying the output JSON format
- Edit `Quick_sort_app.html`, Step 5 section
- Look for JSON generation logic around line 428-436
- URL base: `https://courseroom.capella.edu/courses/`

### Changing the database schema
- Edit `database.js` - update CREATE TABLE statement
- Delete `praxis_database.db` to recreate (or write migration)

### Adding API endpoints
- Edit `server.js`
- Follow existing pattern for `/api/runs`

### Debugging CSV parsing issues
- Check `Quick_sort_app.html` functions: `parseCsvFile()`, `parseCsvHeaders()`
- Data type coercion happens during processing (IDs converted to strings)

## Running the Application

### Easy Way (Recommended)
1. Install [Node.js](https://nodejs.org/) if you don't have it (download the LTS version)
2. Double-click `start.bat`
3. The app opens automatically in your browser

### Manual Way (for developers)
```bash
npm install          # First time only
node server.js       # Start server
# Open http://localhost:3000 in browser
```

## Testing

No automated tests currently exist. Manual testing workflow:
1. Start server with `node server.js`
2. Upload sample CSVs from project root (enrollments.csv, courses.csv, users.csv)
3. Create a test bots.csv with bot_name and bot_id columns
4. Walk through all 6 steps
5. Verify JSON output format

## Important Notes

- All CSV processing happens client-side (browser) - no server-side parsing
- The app is designed for local use only, not production deployment
- Large CSV files may slow the browser due to in-memory processing
- **Auto-save**: Progress is automatically saved - you can close the browser and resume later from Run History
- CSV files are stored in `runs/<id>/` folders on disk
- Python utilities are standalone and don't require the Node.js server

## For Detailed Documentation

See the `memory-bank/` folder for in-depth technical documentation:
- `api_documentation.md` - Full API specs with examples
- `databaseContext.md` - Complete schema details
- `systemPatterns.md` - Architecture decisions and patterns
- `techContext.md` - Full tech stack breakdown
